# üìä An√°lise de Dados e Machine Learning: Predi√ß√£o de Pre√ßos de Im√≥veis

## üéØ Objetivo

Este documento demonstra o processo completo de an√°lise de dados e constru√ß√£o de um modelo de machine learning para predizer pre√ßos de im√≥veis. Vamos aprender os conceitos fundamentais de limpeza de dados, pr√©-processamento e regress√£o linear.

## üìö Conceitos que vamos aprender

- **Limpeza de Dados**: Prepara√ß√£o e organiza√ß√£o dos dados
- **Pr√©-processamento**: Transforma√ß√£o de dados para machine learning
- **Feature Engineering**: Cria√ß√£o de caracter√≠sticas para o modelo
- **Regress√£o Linear**: Modelo de predi√ß√£o de valores cont√≠nuos
- **Valida√ß√£o de Modelo**: Verifica√ß√£o da qualidade das predi√ß√µes

---

## üîß Importa√ß√£o das Bibliotecas

Primeiro, vamos importar as bibliotecas necess√°rias. Cada uma tem um papel espec√≠fico:

- **pandas**: Manipula√ß√£o e an√°lise de dados
- **numpy**: Computa√ß√£o num√©rica
- **matplotlib/seaborn**: Visualiza√ß√£o de dados
- **sklearn**: Algoritmos de machine learning
- **scipy**: Estat√≠sticas e testes
- **statsmodels**: An√°lise estat√≠stica avan√ßada

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.formula.api as sm
import scipy.stats as stats
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
```

---

## üìñ Carregamento e Explora√ß√£o dos Dados

### O que √© Limpeza de Dados?

Limpeza de dados √© o processo de identificar e corrigir problemas nos dados antes de usar para an√°lise ou machine learning. Inclui:

- **Dados ausentes**: Valores que n√£o existem
- **Dados duplicados**: Registros repetidos
- **Dados inconsistentes**: Valores que n√£o fazem sentido
- **Formato inadequado**: Dados no formato errado

### Por que √© importante?

Dados sujos = Modelos ruins! A qualidade do modelo depende diretamente da qualidade dos dados.

```python
# Carregando os dados do arquivo CSV
base = pd.read_csv('house_prices.csv', sep='|')

# Visualizando as primeiras linhas
print("Primeiras 5 linhas dos dados:")
print(base.head())

# Informa√ß√µes sobre o dataset
print(f"\nDimens√µes: {base.shape}")
print(f"Colunas: {list(base.columns)}")
print(f"\nTipos de dados:")
print(base.dtypes)
```

---

## üîÑ Pr√©-processamento de Dados

### O que √© Pr√©-processamento?

Pr√©-processamento √© a transforma√ß√£o dos dados brutos em um formato que os algoritmos de machine learning possam entender e usar eficientemente.

### Tipos de Dados e suas Transforma√ß√µes:

#### 1. **Dados Num√©ricos** (tamanho, quantidade_quartos, price)
- **Problema**: Diferentes escalas (tamanho em m¬≤ vs pre√ßo em R$)
- **Solu√ß√£o**: **StandardScaler** - Normaliza os dados para m√©dia 0 e desvio padr√£o 1
- **F√≥rmula**: z = (x - Œº) / œÉ

#### 2. **Dados Categ√≥ricos** (localizacao)
- **Problema**: Algoritmos n√£o entendem texto
- **Solu√ß√£o**: **OneHotEncoder** - Converte categorias em colunas bin√°rias
- **Exemplo**: 'Centro' ‚Üí [1, 0, 0], 'Suburbio' ‚Üí [0, 1, 0], 'Vila' ‚Üí [0, 0, 1]

### Por que fazer isso?
- **Evita vi√©s**: Sem normaliza√ß√£o, vari√°veis com valores maiores dominam o modelo
- **Melhora performance**: Algoritmos convergem mais r√°pido
- **Facilita interpreta√ß√£o**: Coeficientes ficam compar√°veis

```python
# Criando o pr√©-processador
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['tamanho', 'quantidade_quartos', 'price']), # Dados num√©ricos
        ('cat', OneHotEncoder(), ['localizacao']) # Dados categ√≥ricos
    ])

# Aplicando as transforma√ß√µes aos dados
base_transformed = preprocessor.fit_transform(base)

# Convertendo de volta para DataFrame para visualiza√ß√£o
base_transformed_df = pd.DataFrame(
    base_transformed, 
    columns=['price_scaled', 'tamanho_scaled', 'quantidade_quartos_scaled', 
             'localizacao_Centro', 'localizacao_Suburbio', 'localizacao_Vila']
)

print("Dados transformados com sucesso!")
print("\nPrimeiras 5 linhas dos dados transformados:")
print(base_transformed_df.head())
```

---

## üîç An√°lise de Correla√ß√£o

### O que √© Correla√ß√£o?

Correla√ß√£o mede a for√ßa e dire√ß√£o da rela√ß√£o linear entre duas vari√°veis.

- **Correla√ß√£o = +1**: Rela√ß√£o linear positiva perfeita
- **Correla√ß√£o = -1**: Rela√ß√£o linear negativa perfeita
- **Correla√ß√£o = 0**: Nenhuma rela√ß√£o linear

### Por que analisar correla√ß√£o?
- **Identificar padr√µes**: Quais vari√°veis est√£o relacionadas
- **Detectar multicolinearidade**: Vari√°veis muito correlacionadas podem causar problemas
- **Feature selection**: Vari√°veis com baixa correla√ß√£o com o target podem ser removidas

```python
# Calculando a matriz de correla√ß√£o
corr = base_transformed_df.corr()

# Criando um heatmap para visualizar as correla√ß√µes
plt.figure(figsize=(10, 8))
sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f', center=0)
plt.title('Matriz de Correla√ß√£o - Dados Transformados')
plt.show()

print("\nInterpreta√ß√£o das correla√ß√µes:")
print("‚Ä¢ Valores pr√≥ximos de +1: Correla√ß√£o positiva forte")
print("‚Ä¢ Valores pr√≥ximos de -1: Correla√ß√£o negativa forte")
print("‚Ä¢ Valores pr√≥ximos de 0: Baixa correla√ß√£o")
```

---

## ü§ñ Constru√ß√£o do Modelo de Machine Learning

### O que √© Regress√£o Linear?

Regress√£o linear √© um algoritmo que encontra a melhor linha reta para prever uma vari√°vel cont√≠nua (pre√ßo) baseada em outras vari√°veis (caracter√≠sticas).

### F√≥rmula Matem√°tica:
**y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô + Œµ**

Onde:
- **y**: Vari√°vel que queremos prever (pre√ßo)
- **Œ≤‚ÇÄ**: Intercepto (valor base)
- **Œ≤·µ¢**: Coeficientes (peso de cada caracter√≠stica)
- **x·µ¢**: Caracter√≠sticas (tamanho, quartos, localiza√ß√£o)
- **Œµ**: Erro (diferen√ßa entre predi√ß√£o e valor real)

### Por que Regress√£o Linear?
- **Simples e interpret√°vel**: F√°cil de entender
- **R√°pido**: Computacionalmente eficiente
- **Baseline**: Bom ponto de partida para comparar outros modelos
- **Est√°vel**: Menos propenso a overfitting

```python
# Preparando os dados para o modelo
X = base_transformed_df.drop('price_scaled', axis=1)  # Features
y = base_transformed_df['price_scaled']               # Target

print(f"Dimens√µes dos dados:")
print(f"X (features): {X.shape}")
print(f"y (target): {y.shape}")
print(f"\nFeatures utilizadas: {list(X.columns)}")

# Criando o pipeline do modelo
pipeline = Pipeline(steps=[('model', LinearRegression())])

# Dividindo os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"\nDivis√£o dos dados:")
print(f"Treino: {X_train.shape[0]} amostras")
print(f"Teste: {X_test.shape[0]} amostras")

# Treinando o modelo
pipeline.fit(X_train, y_train)
print("\nModelo treinado com sucesso!")
```

---

## üìä An√°lise de Res√≠duos

### O que s√£o Res√≠duos?

Res√≠duos s√£o a diferen√ßa entre os valores reais e os valores preditos pelo modelo:
**Res√≠duo = Valor Real - Valor Predito**

### Por que analisar res√≠duos?
- **Verificar qualidade do modelo**: Res√≠duos pequenos = bom modelo
- **Detectar padr√µes**: Res√≠duos com padr√£o indicam problemas
- **Validar suposi√ß√µes**: Regress√£o linear assume res√≠duos normalmente distribu√≠dos

### Suposi√ß√µes da Regress√£o Linear:
1. **Linearidade**: Rela√ß√£o linear entre features e target
2. **Independ√™ncia**: Res√≠duos s√£o independentes
3. **Homocedasticidade**: Vari√¢ncia constante dos res√≠duos
4. **Normalidade**: Res√≠duos seguem distribui√ß√£o normal

```python
# Fazendo predi√ß√µes no conjunto de treino
y_train_pred = pipeline.predict(X_train)

# Calculando os res√≠duos
residuals = y_train - y_train_pred

print(f"Estat√≠sticas dos res√≠duos:")
print(f"M√©dia: {residuals.mean():.4f}")
print(f"Desvio Padr√£o: {residuals.std():.4f}")
print(f"M√≠nimo: {residuals.min():.4f}")
print(f"M√°ximo: {residuals.max():.4f}")

# Criando QQ Plot para verificar normalidade
plt.figure(figsize=(10, 6))
stats.probplot(residuals, dist="norm", plot=plt)
plt.title('QQ Plot dos Res√≠duos - Verifica√ß√£o de Normalidade')
plt.xlabel('Quantis Te√≥ricos')
plt.ylabel('Quantis dos Res√≠duos')
plt.grid(True, alpha=0.3)
plt.show()

print("\nInterpreta√ß√£o do QQ Plot:")
print("‚Ä¢ Pontos na linha reta: Res√≠duos normais ‚úÖ")
print("‚Ä¢ Pontos fora da linha: Res√≠duos n√£o normais ‚ùå")
```

```python
# Teste de Shapiro-Wilk para normalidade
stat, p_value = stats.shapiro(residuals)

print(f"Teste de Shapiro-Wilk para Normalidade:")
print(f"Estat√≠stica de Teste: {stat:.3f}")
print(f"Valor-p: {p_value:.3f}")

print("\nInterpreta√ß√£o do Teste:")
print("‚Ä¢ Estat√≠stica pr√≥xima de 1: Dados normais ‚úÖ")
print("‚Ä¢ Valor-p > 0.05: N√£o rejeitamos a hip√≥tese de normalidade ‚úÖ")
print("‚Ä¢ Valor-p ‚â§ 0.05: Rejeitamos a hip√≥tese de normalidade ‚ùå")

if p_value > 0.05:
    print(f"\n‚úÖ Resultado: Res√≠duos s√£o normalmente distribu√≠dos (p = {p_value:.3f})")
else:
    print(f"\n‚ùå Resultado: Res√≠duos N√ÉO s√£o normalmente distribu√≠dos (p = {p_value:.3f})")

print("\nImplica√ß√µes:")
print("‚Ä¢ Res√≠duos normais: Modelo est√° bem especificado")
print("‚Ä¢ Res√≠duos n√£o normais: Pode indicar necessidade de transforma√ß√µes ou modelo diferente")
```

---

## üöÄ Modelo Final e Predi√ß√µes

### Pipeline Completo

Agora vamos criar o modelo final que combina pr√©-processamento + regress√£o linear em um √∫nico pipeline. Isso garante que:

- **Consist√™ncia**: Mesmas transforma√ß√µes aplicadas em treino e teste
- **Simplicidade**: Um √∫nico objeto para fazer predi√ß√µes
- **Robustez**: Menos chance de erros

### Como Funciona:
1. **Entrada**: Dados brutos (tamanho, localiza√ß√£o, quartos)
2. **Pr√©-processamento**: Normaliza√ß√£o + One-hot encoding
3. **Modelo**: Regress√£o linear
4. **Sa√≠da**: Pre√ßo predito

```python
# Criando o pipeline final completo
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['tamanho', 'quantidade_quartos']), # Features num√©ricas
        ('cat', OneHotEncoder(), ['localizacao']) # Features categ√≥ricas
    ])

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),  # Primeiro: pr√©-processamento
    ('model', LinearRegression())    # Segundo: modelo
])

print("Pipeline final criado!")
print("\nEtapas do pipeline:")
print("1Ô∏è‚É£  Pr√©-processamento: StandardScaler + OneHotEncoder")
print("2Ô∏è‚É£  Modelo: LinearRegression")

# Carregando dados e preparando para treino
data = pd.read_csv('house_prices.csv', sep='|')
X = data.drop('price', axis=1)  # Features
y = data['price']               # Target

# Dividindo dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Treinando o pipeline completo
pipeline.fit(X_train, y_train)

print("\n‚úÖ Pipeline treinado com sucesso!")
print(f"üìä Dados de treino: {X_train.shape[0]} amostras")
print(f"üìä Dados de teste: {X_test.shape[0]} amostras")
```

```python
# Fazendo uma predi√ß√£o de exemplo
features = [400, 'Centro', 2]
features_df = pd.DataFrame([features], columns=['tamanho', 'localizacao', 'quantidade_quartos'])

# Fazendo a predi√ß√£o
price = pipeline.predict(features_df)[0]

print("üè† Predi√ß√£o de Pre√ßo de Im√≥vel")
print("=" * 40)
print(f"üìç Caracter√≠sticas:")
print(f"   ‚Ä¢ Tamanho: {features[0]} m¬≤")
print(f"   ‚Ä¢ Localiza√ß√£o: {features[1]}")
print(f"   ‚Ä¢ Quartos: {features[2]}")
print(f"\nüí∞ Pre√ßo Predito: R$ {price:,.2f}")

print("\nüéØ Como interpretar:")
print("‚Ä¢ O modelo analisou padr√µes nos dados de treino")
print("‚Ä¢ Identificou rela√ß√µes entre caracter√≠sticas e pre√ßos")
print("‚Ä¢ Aplicou essas rela√ß√µes para prever o pre√ßo do novo im√≥vel")
print("‚Ä¢ Quanto mais dados de treino, melhor a predi√ß√£o")
```

---

## üéì Resumo do que Aprendemos

### üìä **Limpeza e Pr√©-processamento de Dados**
- **Import√¢ncia**: Dados limpos = modelos melhores
- **T√©cnicas**: Normaliza√ß√£o, One-hot encoding
- **Ferramentas**: StandardScaler, OneHotEncoder

### ü§ñ **Machine Learning**
- **Algoritmo**: Regress√£o Linear
- **Objetivo**: Predizer valores cont√≠nuos
- **Aplica√ß√£o**: Pre√ßos de im√≥veis

### üîç **Valida√ß√£o de Modelo**
- **An√°lise de res√≠duos**: Verificar qualidade
- **Testes estat√≠sticos**: Shapiro-Wilk
- **Visualiza√ß√µes**: QQ Plot

### üöÄ **Pr√≥ximos Passos**
- Experimentar outros algoritmos (Random Forest, XGBoost)
- Feature engineering mais avan√ßado
- Valida√ß√£o cruzada
- Otimiza√ß√£o de hiperpar√¢metros

### üí° **Conceitos-Chave**
1. **Dados s√£o o combust√≠vel**: Qualidade dos dados determina qualidade do modelo
2. **Pr√©-processamento √© crucial**: Transforma√ß√µes adequadas melhoram performance
3. **Valida√ß√£o √© essencial**: Sempre verificar se o modelo faz sentido
4. **Interpretabilidade importa**: Modelos simples s√£o mais confi√°veis

---

**üéØ Lembre-se**: Machine Learning √© uma jornada iterativa. Comece simples, valide sempre, melhore gradualmente!

---

## üìù C√≥digo Completo

```python
# Importa√ß√£o das bibliotecas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import scipy.stats as stats

# Carregamento dos dados
data = pd.read_csv('house_prices.csv', sep='|')

# Prepara√ß√£o dos dados
X = data.drop('price', axis=1)
y = data['price']

# Cria√ß√£o do pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['tamanho', 'quantidade_quartos']),
        ('cat', OneHotEncoder(), ['localizacao'])
    ])

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', LinearRegression())
])

# Divis√£o dos dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Treinamento do modelo
pipeline.fit(X_train, y_train)

# Predi√ß√£o
features = [400, 'Centro', 2]
features_df = pd.DataFrame([features], columns=['tamanho', 'localizacao', 'quantidade_quartos'])
price = pipeline.predict(features_df)[0]

print(f"Pre√ßo predito: R$ {price:,.2f}")
``` 